{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f88766",
   "metadata": {},
   "source": [
    "# Sentiment analysis for stock price prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54259b",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "This notebook ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dde2d246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in a virtual environment: c:\\mainrism\\imp\\enterprises\\projects\\tweet-stock-sentiment\\.venv\n"
     ]
    }
   ],
   "source": [
    "# Ensure correct packages and settings\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Check if running within a virtual environment\n",
    "if sys.prefix != sys.base_prefix:\n",
    "    print(f\"Running in a virtual environment: {sys.prefix}\")\n",
    "else:\n",
    "    print(\"Not running in a virtual environment. Activate the environment, install the packages and try again.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d904d",
   "metadata": {},
   "source": [
    "### Import and augment Tweet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a5da235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date: 2022-11-21, Last date: 2023-02-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>VADER_Positive</th>\n",
       "      <th>VADER_Negative</th>\n",
       "      <th>VADER_Neutral</th>\n",
       "      <th>VADER_Compound_Sentiment</th>\n",
       "      <th>VADER_Final_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100846</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>2022-11-21 14:30:16+00:00</td>\n",
       "      <td>1.594700e+18</td>\n",
       "      <td>$NFLX $290 to $295. Over $295 to $297-$300-$30...</td>\n",
       "      <td>Turbobob129</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100403</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>2022-11-21 19:33:25+00:00</td>\n",
       "      <td>1.594776e+18</td>\n",
       "      <td>“Most winning trading community, Get next winn...</td>\n",
       "      <td>Smith28301</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100402</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>2022-11-21 19:37:51+00:00</td>\n",
       "      <td>1.594777e+18</td>\n",
       "      <td>**Most profitable trading community. Get up to...</td>\n",
       "      <td>nappedonthebed</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.7264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100401</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>2022-11-21 19:38:53+00:00</td>\n",
       "      <td>1.594777e+18</td>\n",
       "      <td>**Most profitable trading \\nhttps://t.co/U9AUM...</td>\n",
       "      <td>Trades75699329</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.7264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100400</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>2022-11-21 19:39:09+00:00</td>\n",
       "      <td>1.594777e+18</td>\n",
       "      <td>Best place for day trading, swing trading, sto...</td>\n",
       "      <td>Smith28301</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date                   Datetime      Tweet Id  \\\n",
       "100846  2022-11-21  2022-11-21 14:30:16+00:00  1.594700e+18   \n",
       "100403  2022-11-21  2022-11-21 19:33:25+00:00  1.594776e+18   \n",
       "100402  2022-11-21  2022-11-21 19:37:51+00:00  1.594777e+18   \n",
       "100401  2022-11-21  2022-11-21 19:38:53+00:00  1.594777e+18   \n",
       "100400  2022-11-21  2022-11-21 19:39:09+00:00  1.594777e+18   \n",
       "\n",
       "                                                     Text        Username  \\\n",
       "100846  $NFLX $290 to $295. Over $295 to $297-$300-$30...     Turbobob129   \n",
       "100403  “Most winning trading community, Get next winn...      Smith28301   \n",
       "100402  **Most profitable trading community. Get up to...  nappedonthebed   \n",
       "100401  **Most profitable trading \\nhttps://t.co/U9AUM...  Trades75699329   \n",
       "100400  Best place for day trading, swing trading, sto...      Smith28301   \n",
       "\n",
       "        VADER_Positive  VADER_Negative  VADER_Neutral  \\\n",
       "100846           0.000             0.0          1.000   \n",
       "100403           0.298             0.0          0.702   \n",
       "100402           0.129             0.0          0.871   \n",
       "100401           0.202             0.0          0.798   \n",
       "100400           0.208             0.0          0.792   \n",
       "\n",
       "        VADER_Compound_Sentiment  VADER_Final_Sentiment  \n",
       "100846                    0.0000                      0  \n",
       "100403                    0.7783                      1  \n",
       "100402                    0.7264                      1  \n",
       "100401                    0.7264                      1  \n",
       "100400                    0.6369                      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import NVDA tweets CSV into a DataFrame\n",
    "nvda_tweets = pd.read_csv(Path(\"data/nvda-tweets.csv\"))\n",
    "\n",
    "# Remove all rows where 'Datetime' is not a valid date\n",
    "nvda_tweets = nvda_tweets[pd.to_datetime(nvda_tweets['Datetime'], errors='coerce').notnull()]\n",
    "\n",
    "# Convert 'Datetime' column to 'Date' in YYYY-MM-DD format\n",
    "nvda_tweets['Date'] = pd.to_datetime(nvda_tweets['Datetime']).dt.date\n",
    "\n",
    "# Sort by Date ascending\n",
    "nvda_tweets = nvda_tweets.sort_values(by='Date')\n",
    "\n",
    "# Remove unnammed columns\n",
    "nvda_tweets = nvda_tweets.loc[:, ~nvda_tweets.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Move Date to the first column\n",
    "colsToShow = nvda_tweets.columns.tolist()\n",
    "colsToShow = [colsToShow[-1]] + colsToShow[:-1]\n",
    "nvda_tweets = nvda_tweets[colsToShow]\n",
    "\n",
    "# First and last dates\n",
    "firstDate = nvda_tweets['Date'].min()\n",
    "lastDate = nvda_tweets['Date'].max()\n",
    "print(f\"First date: {firstDate}, Last date: {lastDate}\")\n",
    "\n",
    "# Add sentiment analysis columns to the Tweets DataFrame\n",
    "nvda_tweets['VADER_Positive'] = 0.0\n",
    "nvda_tweets['VADER_Negative'] = 0.0\n",
    "nvda_tweets['VADER_Neutral'] = 0.0\n",
    "nvda_tweets['VADER_Compound_Sentiment'] = 0.0\n",
    "nvda_tweets['VADER_Final_Sentiment'] = 0\n",
    "\n",
    "# Iterate over each tweet and calculate sentiment scores\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for index, row in nvda_tweets.iterrows():\n",
    "    tweet = row['Text']\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    nvda_tweets.at[index, 'VADER_Positive'] = vs['pos']\n",
    "    nvda_tweets.at[index, 'VADER_Negative'] = vs['neg']\n",
    "    nvda_tweets.at[index, 'VADER_Neutral'] = vs['neu']\n",
    "    nvda_tweets.at[index, 'VADER_Compound_Sentiment'] = vs['compound']\n",
    "    if vs['compound'] >= 0.05:\n",
    "        nvda_tweets.at[index, 'VADER_Final_Sentiment'] = 1\n",
    "    elif vs['compound'] <= -0.05:\n",
    "        nvda_tweets.at[index, 'VADER_Final_Sentiment'] = -1\n",
    "    else:\n",
    "        nvda_tweets.at[index, 'VADER_Final_Sentiment'] = 0\n",
    "\n",
    "# Save the updated tweets DataFrame to a new CSV\n",
    "nvda_tweets.to_csv(Path(\"data/nvda-tweets-augmented.csv\"), index=False)\n",
    "\n",
    "# Preview\n",
    "nvda_tweets.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831fea3b",
   "metadata": {},
   "source": [
    "### Import and augment stock prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df0811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NVDA daily stock prices CSV into a DataFrame\n",
    "nvda_prices = pd.read_csv(Path(\"data/nvda-daily-stock-prices.csv\"))\n",
    "\n",
    "# Convert 'Datetime' column to 'Date' in YYYY-MM-DD format\n",
    "nvda_prices['Date'] = pd.to_datetime(nvda_prices['Date']).dt.date\n",
    "\n",
    "# Sort by Date ascending\n",
    "nvda_prices = nvda_prices.sort_values(by='Date')\n",
    "\n",
    "# Add if the stock price increased compared to the previous day\n",
    "nvda_prices['Price_Up'] = 0\n",
    "nvda_prices['Price_Change'] = 0.0\n",
    "nvda_prices['Price_Change_Pct'] = 0.0\n",
    "\n",
    "for i in range(1, len(nvda_prices)):\n",
    "    if nvda_prices.at[i, 'Close'] > nvda_prices.at[i - 1, 'Close']:\n",
    "        nvda_prices.at[i, 'Price_Up'] = 1\n",
    "    else:\n",
    "        nvda_prices.at[i, 'Price_Up'] = 0\n",
    "    nvda_prices.at[i, 'Price_Change'] = nvda_prices.at[i, 'Close'] - nvda_prices.at[i - 1, 'Close']\n",
    "    if nvda_prices.at[i - 1, 'Close'] != 0:\n",
    "        nvda_prices.at[i, 'Price_Change_Pct'] = (nvda_prices.at[i, 'Price_Change'] / nvda_prices.at[i - 1, 'Close']) * 100\n",
    "    else:\n",
    "        nvda_prices.at[i, 'Price_Change_Pct'] = 0.0\n",
    "\n",
    "# Add the average sentiment per day to the stock prices DataFrame\n",
    "daily_sentiment = nvda_tweets.groupby('Date').agg({\n",
    "    'VADER_Positive': 'mean',\n",
    "    'VADER_Negative': 'mean',\n",
    "    'VADER_Neutral': 'mean',\n",
    "    'VADER_Compound_Sentiment': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge daily sentiment with stock prices on Date\n",
    "nvda_prices = pd.merge(nvda_prices, daily_sentiment, how='left', left_on='Date', right_on='Date')\n",
    "\n",
    "# Save the updated stock prices DataFrame to a new CSV\n",
    "nvda_prices.to_csv(Path(\"data/nvda-daily-stock-prices-augmented.csv\"), index=False)\n",
    "\n",
    "# Amount of data\n",
    "print(f\"NVDA stock prices data points: {len(nvda_prices)}\")\n",
    "\n",
    "# Preview\n",
    "nvda_prices.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0e90b",
   "metadata": {},
   "source": [
    "### Adding new features to the Stock Prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbdabcf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['Compound', 'Negative', 'Neutral', 'Positive'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Add the average sentiment scores per day to the stock prices DataFrame\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m daily_sentiment = \u001b[43mnvda_tweets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPositive\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNegative\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNeutral\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCompound\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.reset_index()\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Merge daily sentiment with stock prices on 'Date'\u001b[39;00m\n\u001b[32m     10\u001b[39m nvda_prices_and_sentiment = pd.merge(nvda_prices, daily_sentiment, on=\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mainrism\\imp\\enterprises\\projects\\tweet-stock-sentiment\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1431\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1434\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mainrism\\imp\\enterprises\\projects\\tweet-stock-sentiment\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:190\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mainrism\\imp\\enterprises\\projects\\tweet-stock-sentiment\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:423\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mainrism\\imp\\enterprises\\projects\\tweet-stock-sentiment\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1603\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1598\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1600\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1601\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1602\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m     result_index, result_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1606\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mainrism\\imp\\enterprises\\projects\\tweet-stock-sentiment\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:462\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    460\u001b[39m is_groupby = \u001b[38;5;28misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[32m    461\u001b[39m func = cast(AggFuncTypeDict, \u001b[38;5;28mself\u001b[39m.func)\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m func = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalize_dictlike_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m is_non_unique_col = (\n\u001b[32m    465\u001b[39m     selected_obj.ndim == \u001b[32m2\u001b[39m\n\u001b[32m    466\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m selected_obj.columns.nunique() < \u001b[38;5;28mlen\u001b[39m(selected_obj.columns)\n\u001b[32m    467\u001b[39m )\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m selected_obj.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    470\u001b[39m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mainrism\\imp\\enterprises\\projects\\tweet-stock-sentiment\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:663\u001b[39m, in \u001b[36mApply.normalize_dictlike_arg\u001b[39m\u001b[34m(self, how, obj, func)\u001b[39m\n\u001b[32m    661\u001b[39m     cols = Index(\u001b[38;5;28mlist\u001b[39m(func.keys())).difference(obj.columns, sort=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m do not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    665\u001b[39m aggregator_types = (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: \"Column(s) ['Compound', 'Negative', 'Neutral', 'Positive'] do not exist\""
     ]
    }
   ],
   "source": [
    "# Add the average sentiment scores per day to the stock prices DataFrame\n",
    "daily_sentiment = nvda_tweets.groupby('Date').agg({\n",
    "    'Positive': 'mean',\n",
    "    'Negative': 'mean',\n",
    "    'Neutral': 'mean',\n",
    "    'Compound': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge daily sentiment with stock prices on 'Date'\n",
    "nvda_prices_and_sentiment = pd.merge(nvda_prices, daily_sentiment, on='Date', how='left')\n",
    "nvda_prices_and_sentiment.head()\n",
    "\n",
    "# Add a 'Sentiment' column based on the 'Compound' score\n",
    "def sentiment_from_compound(compound):\n",
    "    if pd.isna(compound):\n",
    "        return 'No Data'\n",
    "    elif compound >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "nvda_prices_and_sentiment['Sentiment'] = nvda_prices_and_sentiment['Compound'].apply(sentiment_from_compound)\n",
    "\n",
    "# Sort by Date ascending\n",
    "nvda_prices_and_sentiment = nvda_prices_and_sentiment.sort_values(by='Date')\n",
    "\n",
    "# Count how many days have each sentiment\n",
    "print(nvda_prices_and_sentiment['Sentiment'].value_counts())\n",
    "\n",
    "# Get the lowest, highest, and average Compound scores\n",
    "lowest_compound = nvda_prices_and_sentiment['Compound'].min()\n",
    "highest_compound = nvda_prices_and_sentiment['Compound'].max()\n",
    "average_compound = nvda_prices_and_sentiment['Compound'].mean()\n",
    "print(f\"Lowest Compound: {lowest_compound}, Highest Compound: {highest_compound}, Average Compound: {average_compound}\")\n",
    "\n",
    "# Add if the stock price went up or down that day\n",
    "nvda_prices_and_sentiment['Diff_Close'] = nvda_prices_and_sentiment['Close'].diff()\n",
    "nvda_prices_and_sentiment['Was_A_Buy_Day'] = nvda_prices_and_sentiment['Diff_Close'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "nvda_prices_and_sentiment.to_csv(Path(\"data/nvda-prices-and-sentiment.csv\"), index=False)\n",
    "\n",
    "# Preview the entire DataFrame histogram except for Was_A_Buy_Day\n",
    "colsToShow = ['Open', 'Close', 'Compound', 'Diff_Close']\n",
    "nvda_prices_and_sentiment[colsToShow].hist(bins=30, figsize=(12,8))\n",
    "plt.show()\n",
    "\n",
    "# Boxplots to spot outliers\n",
    "nvda_prices_and_sentiment.plot(kind='box', subplots=True, layout=(4,4), figsize=(12,8))\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(nvda_prices_and_sentiment.corr(numeric_only=True), annot=True, cmap=\"coolwarm\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
